{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abcecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 8 0 (offset 0)\n",
      "Ignoring wrong pointing object 10 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 35 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 93 0 (offset 0)\n",
      "Ignoring wrong pointing object 95 0 (offset 0)\n",
      "Ignoring wrong pointing object 101 0 (offset 0)\n",
      "Ignoring wrong pointing object 167 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from pypdf import PdfReader\n",
    "import os\n",
    "from scipy.stats import zscore\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "def NGramExtractor(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t.isalpha()]\n",
    "\n",
    "    dict_uni, dict_bi, dict_tri, dict_quad = {}, {}, {}, {}\n",
    "\n",
    "    for i in range(len(tokens) - 3):\n",
    "        token1, token2, token3, token4 = tokens[i], tokens[i+1], tokens[i+2], tokens[i+3]\n",
    "\n",
    "        unigrams = token1\n",
    "        bigrams = token1 + \" \" + token2\n",
    "        trigrams = token1 + \" \" + token2 + \" \" + token3\n",
    "        quadgrams = token1 + \" \" + token2 + \" \" + token3 + \" \" + token4\n",
    "\n",
    "        dict_uni[unigrams] = dict_uni.get(unigrams, 0) + 1\n",
    "        dict_bi[bigrams] = dict_bi.get(bigrams, 0) + 1\n",
    "        dict_tri[trigrams] = dict_tri.get(trigrams, 0) + 1\n",
    "        dict_quad[quadgrams] = dict_quad.get(quadgrams, 0) + 1\n",
    "\n",
    "    for i in np.arange(len(tokens) - 3, len(tokens)):\n",
    "        unigrams = tokens[i]\n",
    "        dict_uni[unigrams] = dict_uni.get(unigrams, 0) + 1\n",
    "\n",
    "    for i in np.arange(len(tokens) - 3, len(tokens) - 1):\n",
    "        bigrams = tokens[i] + \" \" + tokens[i + 1]\n",
    "        dict_bi[bigrams] = dict_bi.get(bigrams, 0) + 1\n",
    "\n",
    "    trigram = tokens[-3] + \" \" + tokens[-2] + \" \" + tokens[-1]\n",
    "    dict_tri[trigram] = dict_tri.get(trigram, 0) + 1\n",
    "\n",
    "    return {1: dict_uni, 2: dict_bi, 3: dict_tri, 4: dict_quad}\n",
    "\n",
    "def Extract_NGrams_From_File(my_file):\n",
    "    with open(my_file, 'rb') as pdf_file:\n",
    "        reader = PdfReader(pdf_file)\n",
    "        text = ''\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text().lower()\n",
    "    return NGramExtractor(text)\n",
    "\n",
    "file_gram_map = {}\n",
    "file_list = os.listdir(r\"D:\\Programming\\LAB\\TY\\Machine Learning\\Assignment 4\\Files\")\n",
    "\n",
    "global_map = {1: {}, 2: {}, 3: {}, 4: {}}\n",
    "document_count_map = {1: {}, 2: {}, 3: {}, 4: {}}\n",
    "\n",
    "for file in file_list:\n",
    "    my_file = r\"D:/Programming/LAB/TY/Machine Learning/Assignment 4/Files/\" + file\n",
    "    file_gram_map[my_file] = Extract_NGrams_From_File(my_file)\n",
    "\n",
    "    for i in range(1, 5):\n",
    "        i_gram = file_gram_map[my_file][i]\n",
    "        for key, count in i_gram.items():\n",
    "            global_map[i][key] = global_map[i].get(key, 0) + count\n",
    "            document_count_map[i][key] = document_count_map[i].get(key, 0) + 1\n",
    "\n",
    "def build_ngram_df(n):\n",
    "    document_count_series = pd.Series(document_count_map[n])\n",
    "    gram_count_series = pd.Series(global_map[n])\n",
    "    df = pd.DataFrame({\n",
    "        \"gram_count\": gram_count_series,\n",
    "        \"document_count\": document_count_series\n",
    "    })\n",
    "    df[\"Average_freq\"] = df[\"gram_count\"] / df[\"document_count\"]\n",
    "    return df\n",
    "\n",
    "unigrams = build_ngram_df(1)\n",
    "bigrams = build_ngram_df(2)\n",
    "trigrams = build_ngram_df(3)\n",
    "quadgrams = build_ngram_df(4)\n",
    "\n",
    "# print(unigrams)\n",
    "# print(bigrams)\n",
    "# print(trigrams)\n",
    "# print(quadgrams)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_folder = \"results\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "\n",
    "unigrams.to_csv(os.path.join(output_folder, \"unigrams.csv\"), index=True)\n",
    "bigrams.to_csv(os.path.join(output_folder, \"bigrams.csv\"), index=True)\n",
    "trigrams.to_csv(os.path.join(output_folder, \"trigrams.csv\"), index=True)\n",
    "quadgrams.to_csv(os.path.join(output_folder, \"quadgrams.csv\"), index=True)\n",
    "\n",
    "\n",
    "# z score for unigrams, bigrams, trigrams, quadgrams\n",
    "unigrams['z_score']  = zscore(unigrams['gram_count'])\n",
    "filtered_unigrams    = unigrams[(unigrams['z_score'] > -3) & (unigrams['z_score'] < 3)]\n",
    "\n",
    "bigrams['z_score']   = zscore(bigrams['gram_count'])\n",
    "filtered_bigrams     = bigrams[(bigrams['z_score'] > -3) & (bigrams['z_score'] < 3)]\n",
    "\n",
    "trigrams['z_score']  = zscore(trigrams['gram_count'])\n",
    "filtered_trigrams    = trigrams[(trigrams['z_score'] > -3) & (trigrams['z_score'] < 3)]\n",
    "\n",
    "quadgrams['z_score'] = zscore(quadgrams['gram_count'])\n",
    "filtered_quadgrams   = quadgrams[(quadgrams['z_score'] > -3) & (quadgrams['z_score'] < 3)]\n",
    "\n",
    "\n",
    "# IQR for unigrams, bigrams, trigrams, quadgrams\n",
    "Q1_unigram = unigrams['gram_count'].quantile(0.25)\n",
    "Q3_unigram = unigrams['gram_count'].quantile(0.75)\n",
    "IQR_unigram = Q3_unigram - Q1_unigram\n",
    "\n",
    "filtered_unigrams_iqr = unigrams[\n",
    "    (unigrams['gram_count'] >= Q1_unigram - 1.5 * IQR_unigram) &\n",
    "    (unigrams['gram_count'] <= Q3_unigram + 1.5 * IQR_unigram)\n",
    "]\n",
    "\n",
    "Q1_bigram = bigrams['gram_count'].quantile(0.25)\n",
    "Q3_bigram = bigrams['gram_count'].quantile(0.75)\n",
    "IQR_bigram = Q3_bigram - Q1_bigram\n",
    "\n",
    "filtered_bigrams_iqr = bigrams[\n",
    "    (bigrams['gram_count'] >= Q1_bigram - 1.5 * IQR_bigram) &\n",
    "    (bigrams['gram_count'] <= Q3_bigram + 1.5 * IQR_bigram)\n",
    "]\n",
    "\n",
    "Q1_trigram = trigrams['gram_count'].quantile(0.25)\n",
    "Q3_trigram = trigrams['gram_count'].quantile(0.75)\n",
    "IQR_trigram = Q3_trigram - Q1_trigram\n",
    "\n",
    "filtered_trigrams_iqr = trigrams[\n",
    "    (trigrams['gram_count'] >= Q1_trigram - 1.5 * IQR_trigram) &\n",
    "    (trigrams['gram_count'] <= Q3_trigram + 1.5 * IQR_trigram)\n",
    "]\n",
    "\n",
    "Q1_quadgram = quadgrams['gram_count'].quantile(0.25)\n",
    "Q3_quadgram = quadgrams['gram_count'].quantile(0.75)\n",
    "IQR_quadgram = Q3_quadgram - Q1_quadgram\n",
    "\n",
    "filtered_quadgrams_iqr = quadgrams[\n",
    "    (quadgrams['gram_count'] >= Q1_quadgram - 1.5 * IQR_quadgram) &\n",
    "    (quadgrams['gram_count'] <= Q3_quadgram + 1.5 * IQR_quadgram)\n",
    "]\n",
    "\n",
    "\n",
    "# MAD for unigrams, bigrams, tirgrams, quadgrams\n",
    "median_unigram = unigrams['gram_count'].median()\n",
    "mad_unigram = (unigrams['gram_count'] - median_unigram).abs().median()\n",
    "\n",
    "filtered_unigrams_mad = unigrams[\n",
    "    ((unigrams['gram_count'] - median_unigram).abs() / mad_unigram) < 3\n",
    "]\n",
    "\n",
    "median_bigram = bigrams['gram_count'].median()\n",
    "mad_bigram = (bigrams['gram_count'] - median_bigram).abs().median()\n",
    "\n",
    "filtered_bigrams_mad = bigrams[\n",
    "    ((bigrams['gram_count'] - median_bigram).abs() / mad_bigram) < 3\n",
    "]\n",
    "\n",
    "median_trigram = trigrams['gram_count'].median()\n",
    "mad_trigram = (trigrams['gram_count'] - median_trigram).abs().median()\n",
    "\n",
    "filtered_trigrams_mad = trigrams[\n",
    "    ((trigrams['gram_count'] - median_trigram).abs() / mad_trigram) < 3\n",
    "]\n",
    "\n",
    "median_quadgram = quadgrams['gram_count'].median()\n",
    "mad_quadgram = (quadgrams['gram_count'] - median_quadgram).abs().median()\n",
    "\n",
    "filtered_quadgrams_mad = quadgrams[\n",
    "    ((quadgrams['gram_count'] - median_quadgram).abs() / mad_quadgram) < 3\n",
    "]\n",
    "\n",
    "# Mahalnobis distance multivariate thing for assignment n grams\n",
    "X_unigram = unigrams[['gram_count', 'document_count', 'Average_freq']].values\n",
    "cov_matrix_unigram = np.cov(X_unigram.T)\n",
    "inv_cov_matrix_unigram = np.linalg.inv(cov_matrix_unigram)\n",
    "mean_vector_unigram = X_unigram.mean(axis=0)\n",
    "mdist_unigram = np.array([mahalanobis(x, mean_vector_unigram, inv_cov_matrix_unigram) for x in X_unigram])\n",
    "unigrams['mahalanobis'] = mdist_unigram\n",
    "filtered_unigrams_md = unigrams[unigrams['mahalanobis'] < 3]\n",
    "\n",
    "X_bigram = bigrams[['gram_count', 'document_count', 'Average_freq']].values\n",
    "cov_matrix_bigram = np.cov(X_bigram.T)\n",
    "inv_cov_matrix_bigram = np.linalg.inv(cov_matrix_bigram)\n",
    "mean_vector_bigram = X_bigram.mean(axis=0)\n",
    "mdist_bigram = np.array([mahalanobis(x, mean_vector_bigram, inv_cov_matrix_bigram) for x in X_bigram])\n",
    "bigrams['mahalanobis'] = mdist_bigram\n",
    "filtered_bigrams_md = bigrams[bigrams['mahalanobis'] < 3]\n",
    "\n",
    "X_trigram = trigrams[['gram_count', 'document_count', 'Average_freq']].values\n",
    "cov_matrix_trigram = np.cov(X_trigram.T)\n",
    "inv_cov_matrix_trigram = np.linalg.inv(cov_matrix_trigram)\n",
    "mean_vector_trigram = X_trigram.mean(axis=0)\n",
    "mdist_trigram = np.array([mahalanobis(x, mean_vector_trigram, inv_cov_matrix_trigram) for x in X_trigram])\n",
    "trigrams['mahalanobis'] = mdist_trigram\n",
    "filtered_trigrams_md = trigrams[trigrams['mahalanobis'] < 3]\n",
    "\n",
    "X_quadgram = quadgrams[['gram_count', 'document_count', 'Average_freq']].values\n",
    "cov_matrix_quadgram = np.cov(X_quadgram.T)\n",
    "inv_cov_matrix_quadgram = np.linalg.inv(cov_matrix_quadgram)\n",
    "mean_vector_quadgram = X_quadgram.mean(axis=0)\n",
    "mdist_quadgram = np.array([mahalanobis(x, mean_vector_quadgram, inv_cov_matrix_quadgram) for x in X_quadgram])\n",
    "quadgrams['mahalanobis'] = mdist_quadgram\n",
    "filtered_quadgrams_md = quadgrams[quadgrams['mahalanobis'] < 3]\n",
    "\n",
    "\n",
    "\n",
    "filtered_unigrams.to_csv(\"results/unigrams_zscore.csv\", index=False)\n",
    "filtered_unigrams_iqr.to_csv(\"results/unigrams_iqr.csv\", index=False)\n",
    "filtered_unigrams_mad.to_csv(\"results/unigrams_mad.csv\", index=False)\n",
    "filtered_unigrams_md.to_csv(\"results/unigrams_mahalanobis.csv\", index=False)\n",
    "\n",
    "filtered_bigrams.to_csv(\"results/bigrams_zscore.csv\", index=False)\n",
    "filtered_bigrams_iqr.to_csv(\"results/bigrams_iqr.csv\", index=False)\n",
    "filtered_bigrams_mad.to_csv(\"results/bigrams_mad.csv\", index=False)\n",
    "filtered_bigrams_md.to_csv(\"results/bigrams_mahalanobis.csv\", index=False)\n",
    "\n",
    "filtered_trigrams.to_csv(\"results/trigrams_zscore.csv\", index=False)\n",
    "filtered_trigrams_iqr.to_csv(\"results/trigrams_iqr.csv\", index=False)\n",
    "filtered_trigrams_mad.to_csv(\"results/trigrams_mad.csv\", index=False)\n",
    "filtered_trigrams_md.to_csv(\"results/trigrams_mahalanobis.csv\", index=False)\n",
    "\n",
    "filtered_quadgrams.to_csv(\"results/quadgrams_zscore.csv\", index=False)\n",
    "filtered_quadgrams_iqr.to_csv(\"results/quadgrams_iqr.csv\", index=False)\n",
    "filtered_quadgrams_mad.to_csv(\"results/quadgrams_mad.csv\", index=False)\n",
    "filtered_quadgrams_md.to_csv(\"results/quadgrams_mahalanobis.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
